
-------
GENERAL
-------

this has been optimized for use with CMUCL / SBCL / Allegro.  
OpenMCL has been minimally supported.  Lispworks is a target as well 
but less so as the developers don't have access to it.

Theoretically one can port this to any lisp with a decent
FFI and MOP.  However since those are two of the less
standardized bits of Lisp, in practice this might be
difficult.

From top to bottom, here are the implementation layers:

ELEPHANT package
persistent meta-object, persistent collections
controller
serializer
memutils package
UFFI / implementation specific stuff
libsleepycat.so
Sleepycat 4.2/3

While I loath specials, since you can't change the signature
of slot accessors, in order to pass parameters to the
database / serializer, specials are needed.  Also specials
will probably play nice with threaded lisps.  

-----------------------
CLASSES AND METACLASSES
-----------------------

Persistent classes which the user defines are declared and
instrumented by using the persistent-metaclass.  Ideally
creating persistent versions of class, slot-defintion, et al
would be enough, but in reality various implementations do
things in different ways.

CMUCL / SBCL: their's a bit of work to make class slot
allocation and reader / writer / slot-boundp work right.

Allegro: is using slot-boundp instead of
slot-boundp-using-class inside of shared-initialize, which
necessitates some work.

CMUCL doesn't do non-standard allocation types correctly, so
we've created our own slot definition keyword :transient.
In the future this will change.

Andrew will add some notes here in the future.

-----------
COLLECTIONS
-----------

While we support serializing and persisting a wide class of
Lisp data types, there are problems with persisting
aggregate types (conses, lists, arrays, objects,
hash-tables...)

1) not automatic: there's no way for elephant to know when
you've changed a value in an aggregate object, so you have
to manually restore it back into the slot to get it saved.

example 1: you put a cons into the database.  you change
it's car.  this is not saved unless you resave the cons into
the database.

example 2: slot-1 of obj A (saved in the database) contains
a cons.  you change the car of the cons.  this is not
reflected into the database unless you resave A.

2) merge-conflicts: changing one value and saving an
aggregate will write out the whole aggregate, possibly
blowing away changes other threads have made behind your
back.  this is not protected by transactions!

3) consing, non-lazy and expensive (de)serialization: you
have to serialize/deserialize the entire aggregate every
time you save it or restore it.  This is pretty fast all
things considered, but it's probably better to use
persistent collections.

4) you have to store the entire collection in memory,
whereas one of the points of the database to store large
collections of objects.....

For these and other reasons, we provide a hash-table-like
interface to Berkeley BTrees.  These have many advantages
over ordinary hash-tables from the point of view of
persistence.

There is a separate table for BTrees.  This is because we
use a hand coded C function for sorting, which understands a
little of the serialized data.  It can handle numbers (up to
64-bit bignums -- they are approximated by floats) and
strings (case-insensitive for 8-bit, code-point-order for
16-bit Unicode.)  It should be fast but we don't want a
performance penalty on objects.

Secondary indices are mostly handled on the lisp side,
because of our weird table layout (see below) and to avoid
crossing FFI boundaries.  Some unscientific microbenchmarks
indicated that there was no performance benefit on CMUCL /
SBCL, and only minor benefit (asymptotically nil) on
OpenMCL.  They have a separate table.  Actually two handles
are opened on this table: one which is plain, and one which
is associated to the primary btree table by a no-op indexing
function.  Since we maintain the secondary keys ourselves,
the associated handle is good for gets / cursor traversals.
We use the unassociated handle for updates.

----------
CONTROLLER
----------

The controller is accessed through the special
*store-controller*.  The controller keeps track of

1) the environment handle
2) the DB handle(s)
3) the instance cache
4) the root object

The environment handle and DB handle currently aren't really
exposed.  Eventually they should be, so that tuning flags
can be set on them.

OIDs are generated by a bit of C code, which isn't great,
nor that safe (to get acceptable performance i use
DB_TXN_NOSYNC.)  Waiting for Sleepycat 4.3.

The instance cache is implemented as a values-weak
hash-table.  This is a hash-table where the values can be
collected, and when they are, the entire key-value entry is
deleted.  There are implementations of this on the various
platforms.  The instance cache is there to make
deserialization of persistant objects faster.  Since we
aren't storing values in the objects, objects don't take
that much space.  The cache tuning is left up to the garbage
collector, for better or worse.  (It shouldn't be hard to
set a limit on the size of the cache in terms of number of
instances.)

Garbage collection (pruning unreferenced objects from the
database) will be governed by the root object: reachability
determines liveness.  The root object is a btree collection
with a special OID 0.

TODO: write the garbage collector.

------------
TABLE LAYOUT
------------

only a few file / DB handles should be opened per thread.

the current setup use one big btree table for all slots of
all instances of all classes, keyed on

OID + Slot ID

Collections use 2 tables, one for primaries and one for
secondaries (which supports duplicates.)  They are keyed on

OID + key

The root object is a btree with OID = 0.  Since keys are
lexicographically ordered, this will create cache locality
for items in the same persistent object / collection.  We
use a custom C sorter for the btree tables.

Other layout options:

1) Split object table by slots or classes?
2) Separate or same btree for collections?

-------------------
SERIALIZER: GENERAL
-------------------

** Ian: update this

The serializer should be lisp independant but is machine architecture dependant.  
Serialization depends on endianness and the native size of fixnums (31 bit or 
63 bit) so that a fixnum written on a 64-bit machine would fail on a 32-bit machine
and vice versa.  These restrictions are made for the sake of performance.  To move
machine architectures (i.e. x86-32 to x86-64, or PPC to x86) you'll need to dump
the DB to some format.  (Migration will not work in these instances although someone
is welcome to write a serialization tool that will read foreign formats.  I don't think
the time is worth it compared to other features)

No optimization for specialized arrays at the moment, other
than strings (which should be wickedly fast.)

the serializer and deserializer are recursive etypecase and
conds, respectively.

---------------------------
SERIALIZER: PRIMITIVE TYPES
---------------------------

format: 1 byte header + ...

fixed length records: 

nil: 1 + 0 = 1
fixnum, char: 1 + 32-bits = 5 bytes
long-float: 1 + 8 = 9 bytes
persistent-btree: 1 + 32-bit OID = 5 bytes

variable-length:

string, symbol, pathname: 1 + fixnum byte-length + bytes

under allegro strings appear to be 16-bit unicode (if
*features* has ics).  under lispworks they are 16-bit
unicode according to
http://www.lispworks.com/reference/lw43/FLI-U/html/fli-47.htm#pgfId-888395

CMUCL and OpenMCL have 8-bit strings (char-code-limit = 256
i believe.)

so technically using (:array :char) should do the right
thing under all platforms.  converting from the DB you'll
need to use :external-format :unicode on lispworks and
allegro.  however OpenMCL cannot directly send arrays to C.
so we do some implementation specific stuff.  Lispworks also
cannot do this, but we bail.

persistent-object: 1 + 32-bit OID + class-symbol
positive/negative-bignum: 1 + fixnum byte-length + (unsigned-byte 32)s
rational: 1 + +/- bignum numerator + positive-bignum denominator

TODO: don't store the class-symbol, store a number, lookup
the class in a table.  Have to store the table too
though.....

CMUCL's consing dpb/ldb arithmetic means serializing bignums
conses (but they shouldn't have to!)  Serializing everything
else should not cons (with the exception of maybe symbols
and pathnames.)  SBCL seems much better with this.

Deserialization of fixnums is non-consing.  floats appear to
cons on CMUCL, i'm not sure if this is just because of
non-immediate representations of return values or FFI
translations.  we don't support deserialization of objects
that mess with slot-value.

---------------------------
SERIALIZER: AGGREGATE TYPES
---------------------------

if you really must store non-persistent aggregates, we support:

conses (lists): 1 + car + cdr

arrays (simple and otherwise): 

1 + 1 flags (fill, adjust) and type + 4 rank + (4 dimension)* + 
elements in row-major-order

hash-tables (standard tests only):

1 + 1 flags (test) + 4 num pairs + (key + value)

objects:

1 + symbol (name) + fixnum (# slots) + (symbol of slot + value)*

objects are instantiated with "make-instance", so you will
lose if you're doing something funny.  (in particular: no
required initargs!)

structures aren't currently supported since there are no
portable structure introspection methods.

TODO: support fast C <-> Lisp conversions for some
specialized array types (e.g. (unsigned-byte 32) or
something.)  ANSI only specifies strings and bit-vectors,
though most implementations provide others.

support callables, closures, structures et al.

-----------------
Backend Protocol
-----------------

In generalizing the elephant metaclass and serializer so it can
work with multiple backend we formalized the interface between the
lisp common functionality and the SQL/BDB specific logic.  There
are five protocols backends need to support:

- Controller setup/teardown
- Persistent slot API
- Collection API
- Transaction API
- Symbol ID serialization protocol

** Ian TODO

---------
SLEEPYCAT
---------

Sleepycat is great, but isn't plug and play.  A solid
understanding of Sleepycat will help.  By default we use the
transactional DB.  In particular, there is the possibility
of deadlocks.  I recommend using timeouts
(db-env-set-timeout) or the db_deadlock utility to resolve
conflicts.  They will raise db-errors in your code.  If you
wrap your accesses in with-transaction-retry they will
automatically be aborted and re-run.

for production systems, a combination of replication and
txn_nosync will give great performance while maintaining
ACID.  this is beyond the scope of Elephant (for now.)

db_deadlock, db_checkpoint are candidates for cronjobs if
you're not using timeouts.

Elephant uses the Transactional store.  Transactions are by
default accessed through a special variable
*current-transaction*.  The special *auto-commit* (which
defaults to nil!) is also a special.

TODO: do transactions memory leak?

UFFI is used as much as possible.  Because some
implementations can't call function pointers, and because we
need some convenience functions, there is a thin C wrapper
libsleepycat.c which is provided.  Paul Foley's interface
was considered but 1) we wanted a lower-level interface
optimized for our usage patterns (e.g. DB_DBT_USERMEM
always) 2) we wanted to support more platforms and 3)
license worries (probably not really an issue.)

For performance reasons, and also because threaded
environments require it, we handle our own buffering
(DB_DBT_USERMEM).  Some C pointer arithmetic / memcpy
utility functions are provided to handle buffers.  UFFI
pointer-arithmetic is bignum and therefore consing.

TODO: write faster, lispier versions of the
pointer-arithmetic functions.  This is done for CMUCL /
SBCL.  (Definitely possible under OpenMCL.  Dunno about
Allegro, Lispworks.)

CMUCL et al can't do dynamic-extent buffers, so we use
globals bound to specials, which should be thread-safe if
properly initialized.  While we provide functions talk to
the DB using strings, Elephant itself only uses
"buffer-streams", which are structures which have a
stream-like interface to foreign char buffers for reading /
writing C datatypes.

Lispworks is much happier passing back and forth statically
allocated lisp arrays.  since the general string will almost
never be statically allocated, it is unclear how to use this
optimization.

TODO: locks, and better deadlock support.

under CMUCL: none of the db-get*, db-put* cons.
db-transaction-begin conses 32 bytes, as does
with-transaction et al.  the other operations are expensive,
and they cons, but don't need to be called much.  it is
possible to make with-transaction not cons under CMUCL by
using stack allocation, but you can't set the
*current-transaction* special when you do it.  an
optimization for later.

implementations which respect dynamic-extent (CMUCL or SBCL
don't in many cases) should see better non-consing behavior
hopefully.

There are several BDB specific functions available via the
BDB store-controller.

1) Database compaction: when deleting large swaths of the database
   it helps to compact the disk storage so we free up disk space.
2) Deadlock detection; when running multi-threaded, one lisp
   thread can block another depending on how they're interleaved.
   Also if we have multiple OS processes or machines talking
   to the same DB we can end up with a deadlock situation.
   The typical solution is to run deadlock detection in a separate
   thread or launch a process to do so...